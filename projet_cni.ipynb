{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YcbG5Sd7q-JP"
      },
      "source": [
        "**Installer les dépendances et les configurations**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5ygLzBCAzuo"
      },
      "outputs": [],
      "source": [
        "!apt install libgl1-mesa-glx\n",
        "!pip install easyocr\n",
        "!pip install tensorflow tensorflow-gpu opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nWwJhsYVxpe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from tensorflow.keras.models import Sequential\n",
        "#from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "import os\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "import cv2\n",
        "import imghdr\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "tf.random.set_seed(12051966)\n",
        "import easyocr\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYkMdtJMnQHt"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NFJROF7oMfWd"
      },
      "source": [
        "# **Entrainement**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WZFZgui4rQc0"
      },
      "source": [
        "**Supprimer les images douteuses**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0WQUIDuMcADS"
      },
      "source": [
        "parcourir un répertoire d'images,et vérifier si les fichiers sont valides en termes d'extension et de type d'image, puis supprimer les fichiers qui ne correspondent pas aux critères spécifiés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE4s-rXhXKx4"
      },
      "outputs": [],
      "source": [
        "data_dir = 'images'\n",
        "image_exts = ['jpeg','jpg', 'bmp', 'png']\n",
        "for image_class in os.listdir(data_dir):\n",
        "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
        "        image_path = os.path.join(data_dir, image_class, image)\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            tip = imghdr.what(image_path)\n",
        "            if tip not in image_exts:\n",
        "                print('Image not in ext list {}'.format(image_path))\n",
        "                os.remove(image_path)\n",
        "        except Exception as e:\n",
        "            print('Issue with image {}'.format(image_path))\n",
        "            # os.remove(image_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rSX26vYhsQGX"
      },
      "source": [
        "**Charger les données**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B_XbnOgOdlMI"
      },
      "source": [
        "charger un ensemble de données d'images à partir d'un répertoire, extrer le premier lot d'images et d'étiquettes, puis afficher les huit premières images avec leurs étiquettes correspondantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkX5d63GXdhV"
      },
      "outputs": [],
      "source": [
        "#data = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/images',labels='inferred',label_mode='binary')\n",
        "data = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/images')\n",
        "data_iterator = data.as_numpy_iterator()\n",
        "batch = data_iterator.next()\n",
        "fig, ax = plt.subplots(ncols=8, figsize=(20,20))\n",
        "for idx, img in enumerate(batch[0][:8]):\n",
        "    ax[idx].imshow(img.astype(int))\n",
        "    ax[idx].title.set_text(batch[1][idx])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "us1i_MWLsUje"
      },
      "source": [
        "**Normaliser les données**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OrAR5eSrgLX3"
      },
      "source": [
        "normaliser les valeurs des pixels de chaque image de l'ensemble de données en les divisant par 255, ce qui les ramène à une plage de valeurs entre 0 et 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztfVHhlOYsX5"
      },
      "outputs": [],
      "source": [
        "data = data.map(lambda x,y: (x/255, y))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yaIspQ_YsZy0"
      },
      "source": [
        "**Fractionner les données**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRkUHCdJYtK7"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(data)*.7)\n",
        "val_size = int(len(data)*.2)+1\n",
        "test_size = int(len(data)*.1)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgZHTda0_JEI"
      },
      "outputs": [],
      "source": [
        "print (len(data),train_size, val_size,test_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PuWekcr6g5u7"
      },
      "source": [
        " diviser les données en trois ensembles distincts : l'ensemble d'entraînement, de validation et de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEb_vDHFY0hp"
      },
      "outputs": [],
      "source": [
        "train = data.take(train_size)\n",
        "val = data.skip(train_size).take(val_size)\n",
        "test = data.skip(train_size+val_size).take(test_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q4uqSsDSsesL"
      },
      "source": [
        "**Construire un modèle d'apprentissage en profondeur**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56m7YknFZlTy"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(2, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAmRnH74ZrBd"
      },
      "outputs": [],
      "source": [
        "model.compile('adam', loss=tf.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VBlHbn617-Eo"
      },
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v0A7takdsj73"
      },
      "source": [
        "**Entraînement**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e5fx2MFW70on"
      },
      "source": [
        "effectuer l'entraînement du modèle avec une planification dynamique du taux d'apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2jL1HRjZyKu"
      },
      "outputs": [],
      "source": [
        "logdir='log'\n",
        "lr_base = 2e-4\n",
        "epochs=5\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lr_base * 10**(epoch/epochs))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "hist = model.fit(data, epochs=epochs, validation_data=val, callbacks=[tensorboard_callback,lr_scheduler])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dIRYjAZYsnk4"
      },
      "source": [
        "**Tracer les courbe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfDal51OcDx5"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
        "plt.plot(hist.history['val_accuracy'], color='green', label='val_accuracy')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEGKjC5c8idX"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poXM2S_rQ3CM"
      },
      "outputs": [],
      "source": [
        "lrs =lr_base * (10 ** (np.arange(epochs)/epochs))\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.semilogx(lrs, hist.history[\"loss\"])\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Learning rate vs. loss\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQR303OKcI6U"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UvrqsyBfWnpq"
      },
      "source": [
        "**Make prediction**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iaMb4Ewi8A1a"
      },
      "source": [
        "dans cette partie on fait une prediction, dans le but de tester notre modéle"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "00WBWmj6912g"
      },
      "source": [
        "préparer les données test pour ensuite faire une prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h57NRifGR2k"
      },
      "outputs": [],
      "source": [
        "test = data.skip(train_size+val_size).take(test_size)\n",
        "test_iterator = test.as_numpy_iterator()\n",
        "d=test.as_numpy_iterator().next()\n",
        "X, y = d\n",
        "X_norm=X/255\n",
        "print(len(X_norm),len(y))\n",
        "print(y)\n",
        "nb_img=16"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hrL1Amzq_oxy"
      },
      "source": [
        "visualiser les 16 images avec leurs index et la classe à laquelle elles appartiennent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFfP5axI-4q8"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols=nb_img, figsize=(40,40))\n",
        "for idx, img in enumerate(X[:nb_img]):\n",
        "    ax[idx].imshow(img)\n",
        "    legend=f'N°{idx} \\n classe {y[idx]}'\n",
        "    ax[idx].title.set_text(legend)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VzLRAyQR_29K"
      },
      "source": [
        "effectuer une prédiction sur les données X en utilisant le modèle model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHkf-Q5qdN76"
      },
      "outputs": [],
      "source": [
        "Y=model.predict(X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aSk2KvGvCqTa"
      },
      "source": [
        "effectuer une boucle sur les prédictions y_pred et afficher le type de chaque image prédite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNJbZE3vJKmK"
      },
      "outputs": [],
      "source": [
        "idx:int=0\n",
        "y_pred =  np.argmax(Y,axis=-1)\n",
        "print(y_pred)\n",
        "for pred in y_pred[:nb_img]:\n",
        "  if pred==1 :\n",
        "    print(\"image \",idx,\" CNI\")\n",
        "  else:\n",
        "    print(\"image \",idx,\"autre\")\n",
        "  idx+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23jpTr_RQv5w"
      },
      "outputs": [],
      "source": [
        "print(y_pred[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmuEPPEkRtmH"
      },
      "outputs": [],
      "source": [
        "# test = data.skip(train_size+val_size).take(test_size)\n",
        "# test_iterator = test.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuX9mg7xSkzP"
      },
      "outputs": [],
      "source": [
        "first:bool=True\n",
        "for dd in test_iterator :\n",
        "  xx,yy=dd\n",
        "  temp=np.argmax(model.predict(xx,batch_size=32),axis=-1)\n",
        "\n",
        "  if first :\n",
        "    y_class_pred = temp\n",
        "    y_class_true = np.array(yy)\n",
        "    first=False\n",
        "  else :\n",
        "    y_class_pred=np.append(y_class_pred,temp)\n",
        "    y_class_true= np.append(y_class_true,temp)\n",
        "  print(f'Y_TRUE: {y_class_true}\\nY_PRED= { y_class_pred}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSlymHfUVWa3"
      },
      "outputs": [],
      "source": [
        "y_class_pred,y_class_true"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nP80TjIKs0TW"
      },
      "source": [
        "**Draw confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiaG4YCuKfq2"
      },
      "outputs": [],
      "source": [
        "# Source code credit for this function: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823\n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    confusion_matrix: numpy.ndarray\n",
        "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix.\n",
        "        Similarly constructed ndarrays can also be used.\n",
        "    class_names: list\n",
        "        An ordered list of class names, in the order they index the given confusion matrix.\n",
        "    figsize: tuple\n",
        "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
        "        the second determining the vertical size. Defaults to (10,7).\n",
        "    fontsize: int\n",
        "        Font size for axes labels. Defaults to 14.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    matplotlib.figure.Figure\n",
        "        The resulting confusion matrix figure\n",
        "    \"\"\"\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('Truth')\n",
        "    plt.xlabel('Prediction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Esslog2neTBb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_true=y_class_true,y_pred=y_class_pred)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RquI7ET5qtiO"
      },
      "outputs": [],
      "source": [
        "class_names=[\"autre\",\"cni\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "372kZReoRGSU"
      },
      "outputs": [],
      "source": [
        "for i in y :\n",
        "  print (i, class_names[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB092jLpgsiY"
      },
      "outputs": [],
      "source": [
        "from operator import xor\n",
        "print(xor(y_class_true,y_class_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1TNCsF-lXwQ"
      },
      "outputs": [],
      "source": [
        "print_confusion_matrix(cm,class_names=class_names)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "riSChy2VtBta"
      },
      "source": [
        "**Save model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTBar0JjRuPS"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# Open a file and use dump()\n",
        "with open('models/cniClasses.pkl', 'wb') as file:\n",
        "    # A new file will be created\n",
        "    pickle.dump(class_names, file)\n",
        "model.save(\"models/cni_classification\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rDdIcD96tDSC"
      },
      "source": [
        "# **Start inferance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YiUSzG8SfrQ"
      },
      "outputs": [],
      "source": [
        "def inferance(filename):\n",
        "    model = keras.models.load_model('models/cni_classification')\n",
        "    # model.summary()\n",
        "\n",
        "    with open('models/cniClasses.pkl', 'rb') as file:\n",
        "        class_names = pickle.load(file)\n",
        "\n",
        "    img=cv2.imread(filename)\n",
        "    resize = tf.image.resize(img, (256,256))\n",
        "    predictions = model.predict(np.expand_dims(resize/255, 0))\n",
        "    index = predictions.argmax()\n",
        "    predicted_class_name = class_names[index]\n",
        "    return predicted_class_name, predictions[0][index]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "E87S0M9Jv2al"
      },
      "source": [
        "# **Detect cni areas and apply ocr**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kTB-5NzIxzAT"
      },
      "source": [
        "**Detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1N7a8aFxiz-"
      },
      "outputs": [],
      "source": [
        "def smooth(img,type=\"mean\",kernel=9) : # type : convol, mean, median, sd...\n",
        "\n",
        "    img1 = img.copy()\n",
        "\n",
        "    border = (kernel-1)/2\n",
        "\n",
        "    border = int(border)\n",
        "\n",
        "    if (len(img.shape)==3) :\n",
        "\n",
        "        colored = img.shape[2]\n",
        "\n",
        "    else :\n",
        "\n",
        "        img = img.reshape(img.shape[0],img.shape[1],1)\n",
        "\n",
        "        img1 =img1.reshape(img1.shape[0],img1.shape[1],1)\n",
        "\n",
        "        colored = 1\n",
        "\n",
        "    for color in range(0,colored) :\n",
        "\n",
        "        lignemax = (img.shape[0]-border-1)\n",
        "\n",
        "        lignemax = int(lignemax)\n",
        "\n",
        "        for ligne in range(0,img.shape[0]) :\n",
        "\n",
        "            for colonne in range(0,img.shape[1]) :\n",
        "\n",
        "                lignemin = (ligne-border)\n",
        "\n",
        "                if (lignemin<0) :lignemin=0\n",
        "\n",
        "                lignemax = (ligne+border+1)\n",
        "\n",
        "                if (lignemax>(img.shape[0]-1)) : lignemax = img.shape[0]-1\n",
        "\n",
        "                colmin = (colonne-border)\n",
        "\n",
        "                if colmin < 0 : colmin=0\n",
        "\n",
        "                colmax = (colonne+border+1)\n",
        "\n",
        "                if colmax>(img.shape[1]-1) : colmax = img.shape[1]-1\n",
        "\n",
        "                extrait = img[lignemin:lignemax,colmin:colmax,(color):(color+1)]\n",
        "\n",
        "                if type == \"mean\" :\n",
        "\n",
        "                    new_value = np.mean(extrait)\n",
        "\n",
        "                elif type == \"median\" :\n",
        "\n",
        "                    new_value = np.median(extrait)\n",
        "\n",
        "                elif type == \"sd\" :\n",
        "\n",
        "                    new_value = np.std(extrait, ddof  =1)\n",
        "\n",
        "                img1[ligne,colonne,color] =  new_value\n",
        "\n",
        "    if (colored==1):\n",
        "\n",
        "        img1 = img1.reshape(img.shape[0],img.shape[1])\n",
        "\n",
        "    return(img1)\n",
        "\n",
        "def get_limits(color):\n",
        "\n",
        "    c = np.uint8([[color]])  # here insert the bgr values which you want to convert to hsv\n",
        "    hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    lowerLimit = hsvC[0][0][0] - 10, 100, 100\n",
        "    upperLimit = hsvC[0][0][0] + 10, 255, 255\n",
        "\n",
        "    lowerLimit = np.array(lowerLimit, dtype=np.uint8)\n",
        "    upperLimit = np.array(upperLimit, dtype=np.uint8)\n",
        "\n",
        "    return lowerLimit, upperLimit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Fxk2zawaMk"
      },
      "outputs": [],
      "source": [
        "def detection(filename):\n",
        "    \"\"\"\n",
        "    Détecte des zones spécifiques dans la CNI\n",
        "    filename (str) : chemin d'accès au fichier image\n",
        "    Cette fonction lit une image (CNI) à partir du nom de fichier donné, puis identifier les zones d'intérêt, et renvoie les zones détectées.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(filename)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Flou gaussien pour réduire le bruit\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    # Détecter les contours de Canny\n",
        "    canny = cv2.Canny(blur, 10, 70)\n",
        "    thresh2 = cv2.adaptiveThreshold(canny, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 17, 2)\n",
        "    #**FIND THE CONTOURS OF THE IMAGE\n",
        "    contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # Sélectionner le plus grand contour\n",
        "    cnt = max(contours, key=cv2.contourArea)\n",
        "    # Approximer le contour en un rectangle pour encadrer la CNI\n",
        "    rect = cv2.minAreaRect(cnt)\n",
        "    box = cv2.boxPoints(rect)\n",
        "    box = np.int0(box)\n",
        "    # Dessiner le rectangle sur l'image d'entrée\n",
        "    cv2.drawContours(img, [box], 0, (0, 255, 0), 2)\n",
        "    #Redressement de l’image\n",
        "    center_rect = rect[0]\n",
        "    size = rect[1]\n",
        "    print(size)\n",
        "    angle=rect[2]\n",
        "    if rect[1][0]<rect[1][1]:\n",
        "            angle = 90 -rect[2]\n",
        "    else:\n",
        "            angle = rect[2]\n",
        "    M = cv2.getRotationMatrix2D(center_rect, angle, 1.0)\n",
        "    (h1, w1) = img.shape[:2]\n",
        "    cos = np.abs(M[0, 0])\n",
        "    sin = np.abs(M[0, 1])\n",
        "    new_w = int((w1 * cos) + (h1 * sin))\n",
        "    new_h = int((h1 * cos) + (w1 * sin))\n",
        "    M[0, 2] += (new_w / 2) - center_rect[0]\n",
        "    M[1, 2] += (new_h / 2) - center_rect[1]\n",
        "    new_img = cv2.warpAffine(img, M, (new_w, new_h))\n",
        "    #**CUT OFF OUR CNI\n",
        "    gray = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
        "    # Flou gaussien pour réduire le bruit\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    canny = cv2.Canny(blur, 10, 70)\n",
        "    thresh = cv2.adaptiveThreshold(canny, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 17, 2)\n",
        "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnt2 = max(contours, key=cv2.contourArea)\n",
        "    rect = cv2.minAreaRect(cnt2)\n",
        "    box = cv2.boxPoints(rect)\n",
        "    box = np.int0(box)\n",
        "    cv2.drawContours(new_img, [box], 0, (0, 0, 255), 2)\n",
        "    x, y, w, h = cv2.boundingRect(cnt2)\n",
        "    xmin, xmax = x, x+w\n",
        "    ymin, ymax = y, y+h\n",
        "    region = new_img[ymin:ymax, xmin:xmax]\n",
        "    #resize the image\n",
        "    height =738\n",
        "    weight=1040\n",
        "    Blue=[255,50,10]\n",
        "    resized_image = cv2.resize(region, (weight, height))\n",
        "    img_median = smooth(resized_image,\"median\",9)\n",
        "    lower_blue,upper_blue=get_limits(color=Blue)\n",
        "    plt.imshow(resized_image)\n",
        "    plt.show()\n",
        "    #**FIND THE BLUE ZONE ON CNI\n",
        "    hsv = cv2.cvtColor(img_median, cv2.COLOR_BGR2HSV)\n",
        "    # mask pour couleur bleu\n",
        "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
        "    #eliminer le bruit et améliorer les contours de la zone bleue\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    mask = cv2.erode(mask,kernel,iterations = 1)\n",
        "    mask = cv2.dilate(mask,kernel,iterations = 1)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "    # trouver les contours dans le masque\n",
        "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    cnt = max(contours, key=cv2.contourArea)\n",
        "    rect = cv2.minAreaRect(cnt)\n",
        "    box = cv2.boxPoints(rect)\n",
        "    box = np.int0(box)\n",
        "    cv2.drawContours(resized_image, [box], 0, (0, 255, 0), 2)\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    roi2 = resized_image[y:y+h, x:x+w]\n",
        "  # Vérifier si la zone bleue se trouve en haut de l'image\n",
        "    if y < resized_image.shape[0] / 2:\n",
        "        print(\"La zone bleue est en haut de l'image.\")\n",
        "\n",
        "    else:\n",
        "        print(\"La zone est en bas de l'image .\")\n",
        "        resized_image=cv2.rotate(img, cv2.ROTATE_180)\n",
        "        hsv = cv2.cvtColor(resized_image, cv2.COLOR_BGR2HSV)\n",
        "        mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
        "        kernel = np.ones((5,5),np.uint8)\n",
        "        mask = cv2.erode(mask,kernel,iterations = 1)\n",
        "        mask = cv2.dilate(mask,kernel,iterations = 1)\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "        contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "        cnt = max(contours, key=cv2.contourArea)\n",
        "        rect = cv2.minAreaRect(cnt)\n",
        "        box = cv2.boxPoints(rect)\n",
        "        box = np.int0(box)\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        roi2 = resized_image[y:y+h, x:x+w]\n",
        "    #Vérifier si l'image est en recto ou verso\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
        "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
        "    recto = False\n",
        "    # Détecter les visages dans l'image\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "    if len(faces) > 0:\n",
        "        recto = True\n",
        "        f = faces[0]\n",
        "    result=[recto,resized_image, y, h, x, w]\n",
        "    return result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "quMmwtyFx8Ms"
      },
      "source": [
        "**Detect the front of the cni**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oaXhPVJxwZ8"
      },
      "outputs": [],
      "source": [
        "def detectFront(image , y ,h,x,w ):\n",
        "        \"\"\"\n",
        "        cette fonction detecte les zones du devant d'une cni\n",
        "        \"\"\"\n",
        "        #ID\n",
        "        y2 = y + 60\n",
        "        roi_ID = image[y2:y2+h, x:x+w]\n",
        "        #zone INFO+Photo\n",
        "        y3=y2+roi_ID.shape[0]\n",
        "        roi_INFO_TOTAL = image[y3:y3+(6*h), x:x+w]\n",
        "        #zone MRZ\n",
        "        y4 = y3 + roi_INFO_TOTAL.shape[0] #roi_INFO_TOTAL.shape[0] = heuteur de roi_info_total\n",
        "        roi_MRZ = image[y4:, x:x+w]\n",
        "        #zone INFO\n",
        "        y5 = y2 + roi_ID.shape[0]\n",
        "        x2=x+(w-680)\n",
        "        roi_INFO = image[y3:y3+(4*60), x2:]\n",
        "        #zone Photo\n",
        "        x3=x-(w+750)\n",
        "        roi_PHOTO = image[y3:y3+(6*h), x3:x3+w]\n",
        "        #zone nom\n",
        "        y5 = y2 + h\n",
        "        x2=x+(w-680)\n",
        "        roi_NOM = image[y5:y5+115, x2:]\n",
        "        #zone prenom\n",
        "        y6 = y5 + h\n",
        "        x2=x+(w-680)\n",
        "        roi_PRENOM = image[y6:y6+h, x2:]\n",
        "        #zone date_naiss\n",
        "        y7 = y6 + 75\n",
        "        x2=x+(w-680)\n",
        "        roi_DATE = image[y7:y7+85, x2:]\n",
        "        #zone adresse\n",
        "        y8 = y7 + 62\n",
        "        x2=x+(w-700)\n",
        "        roi_ADR =image[y8:y8+h, x2:]\n",
        "        half_height = roi_ADR.shape[0] // 2\n",
        "        roi_ADRESS = roi_ADR[:half_height, :]\n",
        "        zones=[roi_PHOTO,roi_ID, roi_INFO,roi_MRZ ]\n",
        "        return zones"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kcmqG-5oyKT5"
      },
      "source": [
        "**Detect teh back of the cni**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6Wpf1R4yG64"
      },
      "outputs": [],
      "source": [
        "def detectBack (image):\n",
        "        \"\"\"\n",
        "        cette fonction detecte les zones du verso d'une cni\n",
        "        \"\"\"\n",
        "        h, w, _ = image.shape\n",
        "        half_h = h // 2\n",
        "        moitie_centrale = image[half_h - (h // 4):half_h + (h // 4), :]\n",
        "        return moitie_centrale"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RTiDNvA9Lvdk"
      },
      "source": [
        "**Start ocr**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "labpN13NL0Xg"
      },
      "outputs": [],
      "source": [
        "def recognize(filename):\n",
        "    \"\"\"\n",
        "    filename (str) : chemin d'accès au fichier image\n",
        "    cette fonction applique l'ocr sur les zones détectées avec la fonction detection(filename) et renvoi du text.\n",
        "    \"\"\"\n",
        "    concatenated_text = \"\"\n",
        "    result=detection(filename)\n",
        "    if result[0] == True:\n",
        "        zones=detectFront(result[1],result[2],result[3],result[4],result[5])\n",
        "        plt.imshow(zones[0])\n",
        "        plt.show()\n",
        "        for i in range(1, 4):\n",
        "                image_zone = zones[i]\n",
        "                image=cv2.cvtColor(image_zone,cv2.COLOR_BGR2GRAY)\n",
        "                gray = cv2.cvtColor(image_zone, cv2.COLOR_BGR2GRAY)\n",
        "                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))\n",
        "                morph = cv2.morphologyEx(image_zone, cv2.MORPH_CLOSE, kernel)\n",
        "                bifilter=cv2.bilateralFilter(morph, 9,19,75)\n",
        "                plt.imshow(bifilter,cmap='gray')\n",
        "                plt.show()\n",
        "                if i== 4:\n",
        "                    text=pytesseract.image_to_string(bifilter)\n",
        "                    concatenated_text += text + \"\\n\"\n",
        "                else:\n",
        "                    reader = easyocr.Reader(['fr'],gpu=True)\n",
        "                    result = reader.readtext(bifilter,detail=1)\n",
        "                    for detect in result:\n",
        "                        text = detect[1]\n",
        "                        concatenated_text += text + \"\\n\"\n",
        "    else:\n",
        "        print(\"la cni est en verso \")\n",
        "        info=detectBack(result[1])\n",
        "        bfilter = cv2.bilateralFilter(info, 9, 9, 51)\n",
        "        plt.imshow(bfilter)\n",
        "        plt.show()\n",
        "        reader = easyocr.Reader(['fr'],gpu=True)\n",
        "        result = reader.readtext(bfilter)\n",
        "        for detect in result:\n",
        "            text = detect[1]\n",
        "            concatenated_text += text + \"\\n\"\n",
        "    print(concatenated_text)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nmIm6_JHMrUZ"
      },
      "source": [
        "## **Tests**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfoJ6D1oNeWW"
      },
      "outputs": [],
      "source": [
        "image=\"image_tests/page_0.jpeg\"\n",
        "classe , proba =inferance(image)\n",
        "print(classe, str(proba) + \" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X502g1XERlw8"
      },
      "outputs": [],
      "source": [
        "\n",
        "recognize(image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
